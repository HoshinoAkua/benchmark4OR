{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from wl_test_l2O import wl_test\n",
    "from wl_test_final import WLtest\n",
    "torch.set_printoptions(profile=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def graph_generator(ins_name):\n",
    "    # Create a Gurobi model\n",
    "    m = gp.read(ins_name)\n",
    "    nvars = m.NumVars\n",
    "    # Gurobi handles variables and constraints slightly differently\n",
    "    mvars = m.getVars()\n",
    "    # Sort variables by name (Gurobi does not guarantee order)\n",
    "    mvars = sorted(mvars, key=lambda v: v.VarName)\n",
    "    var_feature = torch.zeros((nvars, 2))\n",
    "\n",
    "    \n",
    "    # Obtain variable features\n",
    "    for n in range(nvars):\n",
    "        var = mvars[n]\n",
    "        obj_coeff = var.Obj\n",
    "        lb = var.LB\n",
    "        ub = var.UB\n",
    "        if ub != float('inf'):\n",
    "            m.addConstr(var <= float('inf'))\n",
    "        if lb != 0:\n",
    "            m.addConstr(var >= 0)\n",
    "        \n",
    "        m.addConstr(var >= lb)\n",
    "        m.addConstr(var <= ub)\n",
    "        m.update()\n",
    "        bin = 1 if var.VType == GRB.BINARY else 0\n",
    "        feature = [obj_coeff, bin]\n",
    "        var_feature[n] = torch.tensor(feature)\n",
    "\n",
    "    # Obtain constraint features\n",
    "    # for i in range(ncons):\n",
    "        # cons = mcons[i]\n",
    "        # sense = cons.Sense\n",
    "        # rhs = cons.RHS\n",
    "        # # lhs = -np.inf  # In Gurobi, the lower bound can be implicitly negative infinity\n",
    "        # b = rhs\n",
    "        # if sense == GRB.EQUAL:\n",
    "            \n",
    "        #     cons_sense = 0.0\n",
    "        # elif sense == GRB.LESS_EQUAL:\n",
    "            \n",
    "        #     cons_sense = -1.0\n",
    "        # elif sense == GRB.GREATER_EQUAL:\n",
    "            \n",
    "        #     cons_sense = 1.0\n",
    "        # else:\n",
    "        #     raise NotImplementedError('我只写了大于等于, 小于等于, 等于')\n",
    "        \n",
    "        # feature = [b, cons_sense]\n",
    "        # cons_feature[i] = torch.tensor(feature)\n",
    "    \n",
    "\n",
    "    ncons = m.NumConstrs\n",
    "    mcons = m.getConstrs()\n",
    "    cons_feature = torch.zeros((ncons, 2))\n",
    "    A = torch.zeros((ncons, nvars))\n",
    "    for i in range(ncons):\n",
    "        cons = mcons[i]\n",
    "        sense = cons.Sense\n",
    "        rhs = cons.RHS\n",
    "        # lhs = -np.inf  # In Gurobi, the lower bound can be implicitly negative infinity\n",
    "        b = rhs\n",
    "        if sense == GRB.EQUAL:\n",
    "            \n",
    "            cons_sense = 0.0\n",
    "        elif sense == GRB.LESS_EQUAL:\n",
    "            \n",
    "            cons_sense = -1.0\n",
    "        elif sense == GRB.GREATER_EQUAL:\n",
    "            \n",
    "            cons_sense = 1.0\n",
    "        else:\n",
    "            raise NotImplementedError('我只写了大于等于, 小于等于, 等于')\n",
    "        \n",
    "        feature = [b, cons_sense]\n",
    "        cons_feature[i] = torch.tensor(feature)\n",
    "        for j in range(nvars):\n",
    "            var = mvars[j]\n",
    "            coeff = m.getCoeff(cons, var)  # Gurobi-specific function for constraint coefficients\n",
    "            A[i, j] = coeff\n",
    "\n",
    "    return A, var_feature, cons_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read LP format model from file /home/hanyizhou/wl_test/lp_generation/test/answer_eoe_gpt-4o-2024-08-06.lp\n",
      "Reading time = 0.00 seconds\n",
      ": 6 rows, 10 columns, 60 nonzeros\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "6\n",
      "Read LP format model from file /home/hanyizhou/wl_test/lp_generation/test/model.lp\n",
      "Reading time = 0.00 seconds\n",
      ": 16 rows, 10 columns, 70 nonzeros\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "16\n",
      "not same\n"
     ]
    }
   ],
   "source": [
    "info1 = graph_generator('/home/hanyizhou/wl_test/lp_generation/test/answer_eoe_gpt-4o-2024-08-06.lp')\n",
    "info2 = graph_generator('/home/hanyizhou/wl_test/lp_generation/test/model.lp')\n",
    "A1 = info1[0]\n",
    "A2 = info2[0]\n",
    "f1 = info1[1]#variable\n",
    "f2 = info2[1]\n",
    "c1 = info1[2]#constrain\n",
    "c2 = info2[2]\n",
    "wltest = WLtest(A1, c1,f1,A2,c2,f2)\n",
    "print(wltest.test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 2]), torch.Size([16, 2]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.shape, c2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
